<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Gu Zhang</title>

    <meta name="author" content="Gu Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Gu Zhang
                </p>
                <p>I am an incoming Ph.D. student in Computer Science at <a href="https://iiis.tsinghua.edu.cn/">Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University</a> under the supervision of Prof. <a href="https://hxu.rocks/">Huazhe Xu</a>. 
                </p>

                <p>
                Currently, I am an undergraduate at <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a> with GPA ranking <b>1</b>/88. My research interest mainly lie in robotics and machine learning, with a particular focus on robotic manipulation and multisensory learning.
                </p>
                <p>
                    During my undergraduate study, I am fortunate to be mentored by Prof. <a href="https://www.mvig.org/">Cewu Lu</a> and Prof. <a href="https://thinklab.sjtu.edu.cn/">Junchi Yan</a>. I am also a research visiting student/visitor at <a href="https://www.mit.edu/">Massachusetts Institute of Technology</a> and <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a> under the supervision of Prof. <a href="https://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a> and Prof. <a href="https://people.csail.mit.edu/ganchuang/">Chuang Gan</a>.
                </p>
                 
                <p style="text-align:center">
                  <a href="blake-nash@sjtu.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ctFTmmgAAAAJ&hl">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/blakery-star">Github</a> &nbsp;/&nbsp;
                  <a href="images/Wechat.jpg">WeChat</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/Gu__Zhang">Twitter</a> &nbsp;/&nbsp;


                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/guzhang.jpeg" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding-bottom: 0;"> <!-- 减少底部的padding -->
                  <h2 style="margin-bottom: 0px;">News</h2> <!-- 减少margin-bottom -->
                </td>
              </tr>
              <tr>
                <td>
                  <ul>
                    <li>[Mar. 2024]:Our paper <strong>3D Diffusion Policy </strong> is released.
                    <li>[Jan. 2024]:One paper <strong>ArrayBot</strong> is accepted by ICRA 2024.</li>
                    <li>[Jan. 2024]:Two papers are accepted by ICLR 2024, one is <strong>spotlight</strong>.</li>
                    <li>[Sep. 2023]:One paper is accepted by NeurIPS 2023.</li>
                    <li>[Jun. 2023]:One paper <strong>Flexible Handover</strong> is accepted by IROS 2023.</li>
                    <li>[Apr. 2023]:One paper <strong>IOT-CL</strong> is accepted by ICML 2023.</li>
                    
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  <sup>*</sup> indicates equal contributions.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

           
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dp3.jpg" alt="clean-usnob" width="240" height="160" style="display:block;margin-left:auto;margin-right:auto;vertical-align:middle;">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">3D Diffusion Policy</span>
                <br>
                <a href="https://yanjieze.com/">Yanjie Ze<sup>*</sup></a>, 
                <strong>Gu Zhang<sup>*</sup></strong>, 
                <a href="https://apex.sjtu.edu.cn/members/kangningzhang@apexlab.org">Kangning Zhang</a>,
                <a href="https://github.com/pummmmpkin">Chenyuan Hu</a>, 
                <a href="https://wang-muhan.github.io/">Muhan Wang</a>
                and <a href="http://hxu.rocks/">Huazhe Xu</a>
                <br>
                <em>Arxiv</em>, 2024
                <br>
                <a href="https://3d-diffusion-policy.github.io/">project page</a> /
                <a href="https://3d-diffusion-policy.github.io/2024_arXiv_DP3.pdf">paper</a> /
                <a href="https://github.com/YanjieZe/3D-Diffusion-Policy">code</a> /
                <a href="https://twitter.com/ZeYanjie/status/1765414787775963232">twitter</a>
                <p></p>
                <p>In this paper, we present 3D Diffusion Policy (DP3), a novel visual imitation learning approach that incorporates the power of 3D visual representations
                  into diffusion policies, a class of conditional action generative
                  models.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/iclr.png" alt="clean-usnob" width="240" height="160" style="display:block;margin-left:auto;margin-right:auto;vertical-align:middle;">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation</span>
                <br>
                <a href="https://si-lynnn.github.io/">Zilin Si<sup>*</sup></a>, 
                <strong>Gu Zhang<sup>*</sup></strong>, 
                <a href="https://www.qingweiben.com/">Qingwei Ben<sup>*</sup></a>,
                <a href="https://www.csail.mit.edu/person/brandon-romero">Branden Romero</a>, 
                <a href="https://www.zhou-xian.com/">Xian Zhou</a>, 
                <a href="https://chaoliu.tech/">Chao Liu</a> 
                and <a href="https://people.csail.mit.edu/ganchuang/">Chuang Gan</a>
                <br>
                <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024
                <br>
                <a href="https://difftactile.github.io/">project page</a> /
                paper coming soon 
                <p></p>
                <p>In this paper, we introduce DIFFTACTILE, a physics-based and fully differentiable tactile simulation system designed to enhance robotic manipulation with dense and physically-accurate tactile feedback.</p>
              </td>
            </tr>
            
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/iros2023.png" alt="clean-usnob" width="240" height="160" style="display:block;margin-left:auto;margin-right:auto;vertical-align:middle;">
                </td>
                <td width="75%" valign="middle">
                  <span class="papertitle">Flexible Handover with Real-Time Robust Dynamic Grasp Trajectory Generation</span>
                  <br>
                  <strong>Gu Zhang</strong>, <a href="https://fang-haoshu.github.io/">Hao-shu Fang</a>, <a href="https://tonyfang.net/">Hongjie Fang</a> and <a href="https://www.mvig.org/">Cewu Lu</a>
                  <br>
                  <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2023 <strong style="color: red;">[Oral]</strong>
                  <br>
                  <a href="https://arxiv.org/abs/2308.15622">paper</a> 
                  <p></p>
                  <p>In this paper, we propose an approach for effective and robust flexible handover, which enables the robot to grasp moving objects with flexible motion trajectories with a high success rate.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/corl.jpeg" alt="clean-usnob" width="240" height="160">
                </td>
                <td width="75%" valign="middle">
                  <span class="papertitle">Thin-Shell Object Manipulations With Differentiable Physics Simulations</span>
                  <br>
                  <a href="https://wangyian-me.github.io/">Yian Wang<sup>*</sup></a>,
                  <a href="https://github.com/Alif-01">Juntian Zheng<sup>*</sup></a>, 
                  <a href="https://www.cnblogs.com/ACMLCZH">Zhehuan Chen</a>, 
                  <a href="https://www.zhou-xian.com/">Xian Zhou</a>, 
                  <strong>Gu Zhang</strong>, 
                  <a href="https://chaoliu.tech/">Chao Liu</a>, 
                  and <a href="https://people.csail.mit.edu/ganchuang/">Chuang Gan</a>
                  <br>
                  <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024 <strong style="color: red;">[Spotlight]</strong>
                  <br>
                  <a href="https://thinshelllab.github.io/">project page</a> /
                  paper coming soon
                  <p> In this paper, we introduce ThinShellLab, a fully differentiable simulation platform tailored for diverse thin-shell material interactions with varying properties.</p>
                  <p></p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/arraybot.jpeg" alt="clean-usnob" width="240" height="160">
                </td>
                <td width="75%" valign="middle">
                  <span class="papertitle">ArrayBot: Reinforcement Learning for Generalizable Distributed Manipulation through Touch</span>
                  <br>
                  <a href="https://steven-xzr.github.io/">Zhengrong Xue<sup>*</sup></a>,
                  <a href="https://openreview.net/profile?id=~Han_Zhang25">Han Zhang<sup>*</sup></a>, 
                  <a href="https://openreview.net/profile?id=~Jingwen_Cheng1">Jingwen Chen</a>, 
                  <a href="https://zhengmaohe.netlify.app/">Zhengmao He</a>, 
                  <a href=https://scholar.google.com/citations?user=jOPXmhIAAAAJ&hl=zh-CN&oi=ao">Yuanchen Ju</a>, 
                  <a href="https://linchangyi1.github.io/">Changyi Lin</a>, 
                  <strong>Gu Zhang</strong>, 
                  and <a href="https://hxu.rocks/">Huazhe Xu</a>
                  <br>
                  <em>International Conference on Robotics and Automation(<strong>ICRA</strong>)</em>, 2024
                  <br>
                  <a href="https://steven-xzr.github.io/ArrayBot/">project page</a> /
                  <a href="https://arxiv.org/pdf/2306.16857">paper</a> 
                  <p> In this paper, we present ArrayBot, a distributed manipulation system consisting of a 16×16 array of vertically sliding pillars integrated with tactile sensors, which can simultaneously support, perceive, and manipulate the tabletop objects.</p>
                  <p></p>
                </td>
              </tr>


            

            
            
            <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/icml2023.jpeg" alt="clean-usnob" width="240" height="160">
                </td>
                <td width="75%" valign="middle">
                  <span class="papertitle">Understanding and Generalizing Contrastive Learning from the Inverse Optimal Transport Perspective</span>
                  <br>
                  <a href="https://www.researchgate.net/profile/Liangliang-Shi-2">Liangliang Shi</a>,
                  <strong>Gu Zhang</strong>, 
                  <a href="https://haoyuzhen.com/">Haoyu Zhen</a>, 
                  and <a href="https://thinklab.sjtu.edu.cn/">Junchi Yan</a>
                  <br>
                  <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2023
                  <br>
                  <a href="https://openreview.net/pdf?id=DBlWCsOy94">paper</a> 
                  <p></p>
                  <p>In this paper, we aim to understand CL with a collective point set matching perspective and formulate CL as a form of inverse optimal transport (IOT).</p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/nips.jpeg" alt="clean-usnob" width="240" height="160">
                </td>
                <td width="75%" valign="middle">
                  <span class="papertitle">Relative Entropic Optimal Transport: a (Prior-aware) Matching Perspective to (Unbalanced) Classification</span>
                  <br>
                  <a href="https://www.researchgate.net/profile/Liangliang-Shi-2">Liangliang Shi</a>,
                  <a href="https://haoyuzhen.com/">Haoyu Zhen</a>, 
                  <strong>Gu Zhang</strong>, 
                  and <a href="https://thinklab.sjtu.edu.cn/">Junchi Yan</a>
                  <br>
                  <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023
                  <br>
                  <a href="https://openreview.net/pdf?id=l61Kp1zBwC">paper</a> 
                  <p></p>
                  <p>In this paper, we propose a new variant of optimal transport, called Relative Entropic Optimal Transport (RE-OT) and verify its effectiveness for inhancing visual learning.</p>
                </td>
              </tr>

              


              


            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td style="padding-bottom: 0;"> <!-- 减少底部的padding -->
                      <h2 style="margin-bottom: 0px;">Selected Awards and Honors</h2> <!-- 减少margin-bottom -->
                    </td>
                  </tr>
                  <tr>
                    <td>
                      <ul>
                        <li>2023: <strong>SenseTime Scholarship (Top30 undergraduate AI researchers nationwide, ¥20000 RMB)</strong></li>
                        <li>2023: Shanghai Scholarship (Top 0.2% Shanghai, ¥8000 RMB)</li>
                        <li>2022: <strong>National Scholarship (Top 0.2% nationwide, ¥8000 RMB)</strong></li>
                        <li>2022: Hanying Juhua Scholarship (Top 15 winners in Zhiyuan Honor College, ¥15000 RMB)</li>
                        <li>2021: <strong>National Scholarship (Top 0.2% nationwide, ¥8000 RMB)</strong></li>
                        <li>2021, 2022: A-level Merit Scholarship (Top 1% SJTU, ¥1500 RMB)</li>
                        <li>2021, 2022: Merit Student (Top 5% SJTU)</li>
                        <li>2020, 2021, 2022, 2023: Zhiyuan Honor Scholarship (Top 5% SJTU, ¥5000 RMB)</li>

                      </ul>
                    </td>
                  </tr>
                </tbody>
              </table>
              
              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td style="padding-bottom: 0;"> <!-- 减少底部的padding -->
                      <h2 style="margin-bottom: -5px;">Academic Performance</h2> <!-- 减少margin-bottom -->
                    </td>
                  </tr>
                  <tr>
                    <td>
                      <ul>
                        <li>GPA: 94.47/100 (or 4.12/4.3), Rank 1/88</li>
                        <li>Achieved A+ in more than 30 Courses.</li>
                      </ul>
                    </td>
                  </tr>
                </tbody>
              </table>
              
              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td style="padding-bottom: 0;"> <!-- 减少底部的padding -->
                      <h2 style="margin-bottom: -5px;">Service</h2> <!-- 减少margin-bottom -->
                    </td>
                  </tr>
                  <tr>
                    <td>
                      <ul>
                        <li>Reviewer: IJCAI 2024</li>
                      </ul>
                    </td>
                  </tr>
                </tbody>
              </table>
              
           

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Selected Awards and Honors</h2>
              </td>
            </tr>
            <tr>
                <td>
                  <ul>
                    <li>2023: Shanghai Scholarship (8000RMB¥)</li>
                    <li>2022: National Scholarship (8000RMB¥)</li>
                    <li>2022: Hanying Juhua Scholarship (15 winners, 15000RMB¥)</li>
                    <li>2021: National Scholarship (8000RMB¥)</li>
                    <li>2021-2022: A-level Excellent Scholarship of SJTU</li>
                </ul>
                   
                </td>
    
            </tr>
            
            
          </tbody></table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Academic Performance</h2>
              </td>
            </tr>
            <tr>
                <td>
                  <ul>
                    <li>GPA: 94.47/100 (or 4.12/4.3), Rank 1/88</li>
                    <li>Achieved A+ in more than 30 Courses.</li>
                </ul>
                   
                </td>
            </tr>
          </tbody></table> -->
            
          
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
